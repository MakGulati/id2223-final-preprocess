{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "import os.path\n",
    "import sys\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 300\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_CLASSES = 5\n",
    "TRAIN_DATA_PATH=\"../input/mayank-cheetah/output/\" #replace with directory containing output folder ccontaining datatset\n",
    "TRANSFORM_IMG = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "#     to normalize between(0.5,0.5)\n",
    "#     transforms.Normalize(mean=[.5, .5, .5],std=[1 ,1, 1]) \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22553"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = torchvision.datasets.ImageFolder(root=TRAIN_DATA_PATH, transform=TRANSFORM_IMG)\n",
    "train_data.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set = torch.utils.data.random_split(train_data, [int(np.floor(0.9*train_data.__len__())),int(train_data.__len__()-np.floor(0.9*train_data.__len__()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = data.DataLoader(train_set, batch_size= BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "val_set = data.DataLoader(val_set, batch_size= BATCH_SIZE, num_workers=4)\n",
    "val_set.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'concrete_cement': 0,\n",
       " 'healthy_metal': 1,\n",
       " 'incomplete': 2,\n",
       " 'irregular_metal': 3,\n",
       " 'other': 4}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #replace with directory containing output folder ccontaining datatset\n",
    "classes = [d for d in os.listdir('../input/mayank-cheetah/output/') if os.path.isdir(os.path.join('../input/mayank-cheetah/output/', d))]\n",
    "classes.sort()\n",
    "class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "class_to_idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRIED THIS BASIC MODEL BUT ACCUARY WAS AROUND 66% SO NOT SUITABLE\n",
    "\n",
    "# class ConvNet(nn.Module):\n",
    "#     def __init__(self, num_classes=NUM_CLASSES):\n",
    "#         super(ConvNet, self).__init__()\n",
    "#         self.layer1 = nn.Sequential(\n",
    "#             nn.Conv2d(3, 24, kernel_size=9, stride=1, padding=0),\n",
    "#             nn.BatchNorm2d(24),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "#         self.layer2 = nn.Sequential(\n",
    "#             nn.Conv2d(24, 48, kernel_size=7, stride=1, padding=0),\n",
    "#             nn.BatchNorm2d(48),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "#         self.layer3 = nn.Sequential(\n",
    "#             nn.Conv2d(48, 96, kernel_size=5, stride=1, padding=0),\n",
    "#             nn.BatchNorm2d(96),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "#         self.layer4 = nn.Sequential(\n",
    "#             nn.Conv2d(96, 192, kernel_size=3, stride=1, padding=0),\n",
    "#             nn.BatchNorm2d(192),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "#         self.fc1 = nn.Sequential(\n",
    "#             nn.Linear(10*10*192, 512),\n",
    "#             nn.ReLU())\n",
    "#         self.fc2 = nn.Sequential(\n",
    "#             nn.Linear(512,128),\n",
    "#             nn.ReLU())\n",
    "#         self.fc3 = nn.Linear(128, num_classes)\n",
    "#         self.sm = nn.Softmax(dim=-1)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         out = self.layer1(x)\n",
    "#         out = self.layer2(out)\n",
    "#         out = self.layer3(out)\n",
    "#         out = self.layer4(out)\n",
    "#         out = out.reshape(out.size(0), -1)\n",
    "#         out = self.fc1(out)\n",
    "#         out = self.fc2(out)\n",
    "#         out = self.fc3(out)\n",
    "#         out = self.sm(out)\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Vgg model for tansfer learning\n",
    "custom_model=torchvision.models.vgg11(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in custom_model.parameters(): #freezing gradients\n",
    "    param.requires_grad = False   \n",
    "\n",
    "#adding custom layers in the end for specfic tasks    \n",
    "custom_model.classifier[-1] = nn.Sequential(\n",
    "               nn.Linear(4096, 512),\n",
    "               nn.ReLU(inplace=True),\n",
    "               nn.Linear(512, 128),\n",
    "               nn.ReLU(inplace=True),\n",
    "               nn.Linear(128, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model = custom_model.to(device)\n",
    "#uncomment to print summary\n",
    "# summary(custom_model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(custom_model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "losses=[]\n",
    "total_step = len(train_set)\n",
    "#start time\n",
    "# torch.cuda.synchronize()\n",
    "since = int(round(time.time()*1000))\n",
    "for epoch in range(EPOCHS):\n",
    "    running_loss=0.0\n",
    "    for i, (images, labels) in enumerate(train_set):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = custom_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        if (i+1) % 1 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, EPOCHS, i+1, total_step, loss.item()))\n",
    "    epoch_loss = running_loss / len(train_set)\n",
    "    losses.append(epoch_loss)\n",
    "#stop time\n",
    "# torch.cuda.synchronize()\n",
    "time_elapsed = int(round(time.time()*1000)) - since\n",
    "print ('training time elapsed {}ms'.format(time_elapsed)) #to print whole training time\n",
    "\n",
    "#saving losses in pickle to plot graph later\n",
    "pickle_out = open(\"dict.pickle\",\"wb\")\n",
    "pickle.dump(losses, pickle_out)\n",
    "pickle_out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for loading weights from previous saved checkpoints\n",
    "custom_model.load_state_dict(torch.load('../input/checkpoints-dict/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "custom_model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "predict_list=[]\n",
    "true_list=[]\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in val_set:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = custom_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predict_list.append(predicted)\n",
    "        true_list.append(labels)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the 2304 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "# Save the model checkpoint\n",
    "# torch.save(custom_model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting training graph\n",
    "\n",
    "with open('../input/checkpoints-dict/dict.pickle', 'rb') as f:\n",
    "    x = pickle.load(f)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('no. of epochs')\n",
    "plt.ylabel('epoch loss')\n",
    "plt.plot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is to verify on particular image if classifies well\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "\n",
    "loader = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor()])\n",
    "\n",
    "def image_loader(image_name):\n",
    "    \"\"\"load image, returns cuda tensor\"\"\"\n",
    "    image = Image.open(image_name).convert(\"RGB\")\n",
    "    image = loader(image).float()\n",
    "    image = image.unsqueeze(0)  #this is for VGG, may not be needed for ResNet\n",
    "    return image.cuda()  #assumes that you're using GPU\n",
    "\n",
    "image = image_loader(\"../input/mayank-cheetah/output/concrete_cement/7a27cc58.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0], device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verification using one image at a time\n",
    "_, predikt= torch.max(custom_model(image).data, 1)\n",
    "predikt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = predict_list[0].cpu().numpy()\n",
    "for i in range(1,val_set.__len__()):\n",
    "    a = np.hstack((a, predict_list[i].cpu().numpy()))\n",
    "b = true_list[0].cpu().numpy()\n",
    "for i in range(1,val_set.__len__()):\n",
    "    b = np.hstack((b, true_list[i].cpu().numpy()))\n",
    "\n",
    "y_actu = pd.Series(b, name='Actual')\n",
    "y_pred = pd.Series(a, name='Predicted')\n",
    "df_confusion = pd.crosstab(y_actu, y_pred, margins=True)\n",
    "idx_to_classes={0:'concrete_cement',\n",
    "  1:'healthy_metal',\n",
    "  2:'incomplete',\n",
    "  3:'irregular_metal',\n",
    "  4: 'other',\n",
    "  }\n",
    "df_confusion_new = df_confusion.rename(columns=idx_to_classes, index=label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confusion_new"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_planet",
   "language": "python",
   "name": "torch_planet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
